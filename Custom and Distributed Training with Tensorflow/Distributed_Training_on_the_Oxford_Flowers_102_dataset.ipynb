{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "93fd8b12-b2af-4513-820d-fd2d5f25ca65",
      "metadata": {
        "id": "93fd8b12-b2af-4513-820d-fd2d5f25ca65"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "36f2ffab-117a-4f6a-8ba3-6d40d9d6d0cf",
      "metadata": {
        "id": "36f2ffab-117a-4f6a-8ba3-6d40d9d6d0cf"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d1f09cad-f8b0-48ba-a27b-a4c4d97e5236",
      "metadata": {
        "id": "d1f09cad-f8b0-48ba-a27b-a4c4d97e5236"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "06d5a05b-70cf-490a-aaef-d8667564d0cb",
      "metadata": {
        "id": "06d5a05b-70cf-490a-aaef-d8667564d0cb"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac7f8d89-8fc1-4363-8055-513b35094eee",
      "metadata": {
        "id": "ac7f8d89-8fc1-4363-8055-513b35094eee"
      },
      "source": [
        "## Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a2f2617b-2471-4594-a867-6280a82cb5df",
      "metadata": {
        "id": "a2f2617b-2471-4594-a867-6280a82cb5df"
      },
      "outputs": [],
      "source": [
        "splits = ['train[:80%]', 'train[80%:90%]', 'train[90%:]']\n",
        "(train_examples, validation_examples, test_examples), info = tfds.load('oxford_flowers102',\n",
        "                                                                     with_info=True, split=splits,\n",
        "                                                                      as_supervised=True, data_dir='data/')\n",
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_examples, num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_gFfHKIBnzO",
        "outputId": "c74e364f-c923-418f-8952-5b3af9fa641c"
      },
      "id": "h_gFfHKIBnzO",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1020, 102)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cb9dd5b-8d9e-47c9-9723-11e7f7710190",
      "metadata": {
        "id": "6cb9dd5b-8d9e-47c9-9723-11e7f7710190"
      },
      "source": [
        "## Create a strategy to distribute the variables and the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0d630333-d5cb-4feb-8e98-f7b28b1ff6f1",
      "metadata": {
        "id": "0d630333-d5cb-4feb-8e98-f7b28b1ff6f1"
      },
      "outputs": [],
      "source": [
        "# If the list of devices is not specified in the\n",
        "# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "539f1534-acc8-4f73-bcb2-4e2f9df7b9d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "539f1534-acc8-4f73-bcb2-4e2f9df7b9d9",
        "outputId": "6cf5c81b-5ca6-4bdf-f938-b616904929b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n"
          ]
        }
      ],
      "source": [
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6f1ab5e-f0b6-4c89-b26f-467b9b22c433",
      "metadata": {
        "id": "f6f1ab5e-f0b6-4c89-b26f-467b9b22c433"
      },
      "source": [
        "## Setup input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a629b52f-b33c-47fa-9fa2-3399566d1553",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a629b52f-b33c-47fa-9fa2-3399566d1553",
        "outputId": "f4302410-7a76-44b6-92dd-5599289e901c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4 with input size (224, 224)\n"
          ]
        }
      ],
      "source": [
        "BUFFER_SIZE = num_examples\n",
        "EPOCHS = 10\n",
        "pixels = 224\n",
        "# MODULE_HANDLE = 'data/resnet_50_feature_vector'\n",
        "MODULE_HANDLE = 'https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4'\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "516c2d8a-3f50-46c8-9a55-27dedfa864c7",
      "metadata": {
        "id": "516c2d8a-3f50-46c8-9a55-27dedfa864c7"
      },
      "outputs": [],
      "source": [
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e152f446-b323-41cb-8613-200716cb7b44",
      "metadata": {
        "id": "e152f446-b323-41cb-8613-200716cb7b44"
      },
      "source": [
        "## Set the global batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8c6b2030-465f-42ac-a4a9-8eaef43decfb",
      "metadata": {
        "id": "8c6b2030-465f-42ac-a4a9-8eaef43decfb"
      },
      "outputs": [],
      "source": [
        "def set_global_batch_size(batch_size_per_replica, strategy):\n",
        "    global_batch_size = batch_size_per_replica * strategy.num_replicas_in_sync\n",
        "    return global_batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "587c0877-44c9-467e-9861-28117b76e0c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "587c0877-44c9-467e-9861-28117b76e0c4",
        "outputId": "a74868d8-7bbe-4477-ba67-0ce83bc7e292"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "GLOBAL_BATCH_SIZE = set_global_batch_size(BATCH_SIZE_PER_REPLICA, strategy)\n",
        "GLOBAL_BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "fe06c4b3-87bb-441f-85f0-9c4ea3c3aa9c",
      "metadata": {
        "id": "fe06c4b3-87bb-441f-85f0-9c4ea3c3aa9c"
      },
      "outputs": [],
      "source": [
        "train_batches = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE_PER_REPLICA).prefetch(1)\n",
        "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE_PER_REPLICA).prefetch(1)\n",
        "test_batches = test_examples.map(format_image).batch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "fa395166-ba7d-4c28-8052-6b7aba9ef253",
      "metadata": {
        "id": "fa395166-ba7d-4c28-8052-6b7aba9ef253"
      },
      "outputs": [],
      "source": [
        "def distribute_datasets(strategy, train_batches, validation_batches, test_batches):\n",
        "\n",
        "    train_dist_dataset = strategy.experimental_distribute_dataset(train_batches)\n",
        "    val_dist_dataset = strategy.experimental_distribute_dataset(validation_batches)\n",
        "    test_dist_dataset = strategy.experimental_distribute_dataset(test_batches)\n",
        "\n",
        "    return train_dist_dataset, val_dist_dataset, test_dist_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "5abf6305-fc9e-4bbf-97c4-db890d2f752a",
      "metadata": {
        "id": "5abf6305-fc9e-4bbf-97c4-db890d2f752a"
      },
      "outputs": [],
      "source": [
        "train_dist_dataset, val_dist_dataset, test_dist_dataset = distribute_datasets(strategy, train_batches, validation_batches, test_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5289e16c-e49d-423d-b3dd-f12d9c03039b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5289e16c-e49d-423d-b3dd-f12d9c03039b",
        "outputId": "876e259a-eae7-4220-ffc7-f68f31c477ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.distribute.input_lib.DistributedDataset'>\n",
            "<class 'tensorflow.python.distribute.input_lib.DistributedDataset'>\n",
            "<class 'tensorflow.python.distribute.input_lib.DistributedDataset'>\n"
          ]
        }
      ],
      "source": [
        "print(type(train_dist_dataset))\n",
        "print(type(val_dist_dataset))\n",
        "print(type(test_dist_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "142ebab0-17ca-4954-a9d5-6b88e52aecd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "142ebab0-17ca-4954-a9d5-6b88e52aecd0",
        "outputId": "ef27532c-86f0-476e-da8e-9fba895cedf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x is a tuple that contains 2 values \n",
            "x[0] contains the features, and has shape (64, 224, 224, 3)\n",
            "  so it has 64 examples in the batch, each is an image that is (224, 224, 3)\n",
            "x[1] contains the labels, and has shape (64,)\n"
          ]
        }
      ],
      "source": [
        "for x in train_dist_dataset:\n",
        "    break\n",
        "\n",
        "print(f\"x is a tuple that contains {len(x)} values \")\n",
        "print(f\"x[0] contains the features, and has shape {x[0].shape}\")\n",
        "print(f\"  so it has {x[0].shape[0]} examples in the batch, each is an image that is {x[0].shape[1:]}\")\n",
        "print(f\"x[1] contains the labels, and has shape {x[1].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ace188b4-963c-43b2-82af-0b265867cd83",
      "metadata": {
        "id": "ace188b4-963c-43b2-82af-0b265867cd83"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d4eb2260-147e-4481-9c38-e8c2fbdb971e",
      "metadata": {
        "id": "d4eb2260-147e-4481-9c38-e8c2fbdb971e"
      },
      "outputs": [],
      "source": [
        "class ResNetModel(tf.keras.Model):\n",
        "    def __init__(self, classes):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self._feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                                 trainable=False)\n",
        "        self._classifier = tf.keras.layers.Dense(classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self._feature_extractor(inputs)\n",
        "        x = self._classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0704110d-69be-48c7-8de1-2adb1156c8b9",
      "metadata": {
        "id": "0704110d-69be-48c7-8de1-2adb1156c8b9"
      },
      "outputs": [],
      "source": [
        "# Create a checkpoint directory to store the checkpoints.\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1353c7e9-e997-452e-8994-8fc9e0f042b9",
      "metadata": {
        "id": "1353c7e9-e997-452e-8994-8fc9e0f042b9"
      },
      "source": [
        "## Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "fdeed22e-cace-414f-b9e6-c351b4198cf4",
      "metadata": {
        "id": "fdeed22e-cace-414f-b9e6-c351b4198cf4"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
        "    def compute_loss(y_true, y_pred):\n",
        "        per_example_loss = loss_object(y_true, y_pred)\n",
        "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca64a1c4-f818-40b3-a12c-36c16ef46b1c",
      "metadata": {
        "id": "ca64a1c4-f818-40b3-a12c-36c16ef46b1c"
      },
      "source": [
        "## Define the metrics to track loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "920ef883-39c8-4ba6-80da-d66ed6b5b27b",
      "metadata": {
        "id": "920ef883-39c8-4ba6-80da-d66ed6b5b27b"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "        name='train_accuracy')\n",
        "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "        name='test_accuracy')\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b31d4a4f-a11f-418d-a7b3-53950011bf28",
      "metadata": {
        "id": "b31d4a4f-a11f-418d-a7b3-53950011bf28"
      },
      "source": [
        "## Instantiate the model, optimizer, and checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "ad520db4-b47c-4f83-b62d-a9c85229619c",
      "metadata": {
        "id": "ad520db4-b47c-4f83-b62d-a9c85229619c"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    model = ResNetModel(num_classes)\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a06705d-cc8b-4539-a874-00f96df7e2ce",
      "metadata": {
        "id": "3a06705d-cc8b-4539-a874-00f96df7e2ce"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "c9ea56d4-7796-49dd-9d0a-7a9fd98a9f28",
      "metadata": {
        "id": "c9ea56d4-7796-49dd-9d0a-7a9fd98a9f28"
      },
      "outputs": [],
      "source": [
        "def train_test_step_fns(strategy, model, compute_loss, optimizer, train_accuracy, loss_object, test_loss, test_accuracy):\n",
        "    with strategy.scope():\n",
        "        def train_step(inputs):\n",
        "            images, labels = inputs\n",
        "            with tf.GradientTape():\n",
        "                predictions = model(images, training=True)\n",
        "                loss = compute_loss(labels, predictions)\n",
        "            gradients = tf.gradients(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients,  model.trainable_variables))\n",
        "\n",
        "            train_accuracy.update_state(labels, predictions)\n",
        "            return loss\n",
        "\n",
        "        def test_step(inputs):\n",
        "            images, labels = inputs\n",
        "            predictions = model(images, training=False)\n",
        "            t_loss = compute_loss(labels, predictions)\n",
        "            test_loss.update_state(t_loss)\n",
        "            test_accuracy.update_state(labels, predictions)\n",
        "\n",
        "    return train_step, test_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "0357d4c0-74c7-422d-ae29-d6748d547d49",
      "metadata": {
        "id": "0357d4c0-74c7-422d-ae29-d6748d547d49"
      },
      "outputs": [],
      "source": [
        "train_step, test_step = train_test_step_fns(strategy, model, compute_loss, optimizer, train_accuracy, loss_object, test_loss, test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "2453ceb1-46a1-4228-9e7c-6cd3c082bad5",
      "metadata": {
        "id": "2453ceb1-46a1-4228-9e7c-6cd3c082bad5"
      },
      "outputs": [],
      "source": [
        "def distributed_train_test_step_fns(strategy, train_step, test_step, model, compute_loss, optimizer, train_accuracy, loss_object, test_loss, test_accuracy):\n",
        "    with strategy.scope():\n",
        "        @tf.function\n",
        "        def distributed_train_step(dataset_inputs):\n",
        "            per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
        "            return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
        "                                   axis=None)\n",
        "\n",
        "        @tf.function\n",
        "        def distributed_test_step(dataset_inputs):\n",
        "            return strategy.run(test_step, args=(dataset_inputs,))\n",
        "\n",
        "        return distributed_train_step, distributed_test_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1107aa14-cad8-484d-9a32-937c6e2436d8",
      "metadata": {
        "id": "1107aa14-cad8-484d-9a32-937c6e2436d8"
      },
      "outputs": [],
      "source": [
        "distributed_train_step, distributed_test_step = distributed_train_test_step_fns(strategy, train_step, test_step, model, compute_loss, optimizer, train_accuracy, loss_object, test_loss, test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "3e6cd907-2796-4a3d-a9dd-09ede1f5bf25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e6cd907-2796-4a3d-a9dd-09ede1f5bf25",
        "outputId": "fc3e1f60-c979-4ae4-bc61-b780573e8013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13it [02:27, 11.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.515346050262451, Accuracy: 4.779411792755127, Test Loss: 0.06089402735233307, Test Accuracy: 11.764705657958984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13it [02:19, 10.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 2.634058952331543, Accuracy: 48.897056579589844, Test Loss: 0.04581480473279953, Test Accuracy: 41.17647171020508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13it [02:18, 10.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 1.58052659034729, Accuracy: 82.96568298339844, Test Loss: 0.03760666400194168, Test Accuracy: 56.86274719238281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13it [03:22, 15.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 1.0048941373825073, Accuracy: 90.68627166748047, Test Loss: 0.03249422833323479, Test Accuracy: 56.86274719238281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13it [02:16, 10.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 0.686842679977417, Accuracy: 95.22058868408203, Test Loss: 0.029490171000361443, Test Accuracy: 62.74510192871094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13it [02:17, 10.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 0.4996119737625122, Accuracy: 97.30392456054688, Test Loss: 0.027804484590888023, Test Accuracy: 66.66667175292969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13it [02:27, 11.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 0.3796531856060028, Accuracy: 98.52941131591797, Test Loss: 0.02612422965466976, Test Accuracy: 68.62745666503906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13it [02:20, 10.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 0.2985183000564575, Accuracy: 99.50980377197266, Test Loss: 0.025496482849121094, Test Accuracy: 68.62745666503906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13it [02:25, 11.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 0.24128498136997223, Accuracy: 99.75489807128906, Test Loss: 0.024948669597506523, Test Accuracy: 67.64705657958984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13it [02:20, 10.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.19785989820957184, Accuracy: 100.0, Test Loss: 0.024284949526190758, Test Accuracy: 70.5882339477539\n"
          ]
        }
      ],
      "source": [
        "with strategy.scope():\n",
        "    for epoch in range(EPOCHS):\n",
        "        # TRAIN LOOP\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "        for x in tqdm(train_dist_dataset):\n",
        "            total_loss += distributed_train_step(x)\n",
        "            num_batches += 1\n",
        "        train_loss = total_loss / num_batches\n",
        "\n",
        "        # TEST LOOP\n",
        "        for x in test_dist_dataset:\n",
        "            distributed_test_step(x)\n",
        "\n",
        "        template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \"\n",
        "                    \"Test Accuracy: {}\")\n",
        "        print (template.format(epoch+1, train_loss,\n",
        "                               train_accuracy.result()*100, test_loss.result(),\n",
        "                               test_accuracy.result()*100))\n",
        "\n",
        "        test_loss.reset_state()\n",
        "        train_accuracy.reset_state()\n",
        "        test_accuracy.reset_state()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkZ-b6gUIY6P",
        "outputId": "5a33aee2-04e1-4ec0-a641-3b2a46b21972"
      },
      "id": "MkZ-b6gUIY6P",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6af609f5-6ff6-4009-bbad-2fcbdc00a0d8",
      "metadata": {
        "id": "6af609f5-6ff6-4009-bbad-2fcbdc00a0d8"
      },
      "outputs": [],
      "source": [
        "save_path = '/content/drive/My Drive/my_model'\n",
        "\n",
        "# Save the model\n",
        "tf.saved_model.save(model, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WyVU5QjlBE3W"
      },
      "id": "WyVU5QjlBE3W",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}